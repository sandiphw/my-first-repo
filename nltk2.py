import nltk
from nltk.tokenize import sent_tokenize
text = "Let us understand the difference between sentence & word tokenizer. It is going to be a simple example."
print(sent_tokenize(text))
